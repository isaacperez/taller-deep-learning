{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aclaración de conceptos\n",
    "\n",
    "\n",
    "- Cómo es una capa de convolucion:\n",
    "\n",
    "<img src=\"convLayer1.png\">\n",
    "<img src=\"convLayer2.png\">\n",
    "<img src=\"convLayer3.png\">\n",
    "<img src=\"convLayer4.png\">\n",
    "<img src=\"convLayer5.png\">\n",
    "<img src=\"convLayer6.png\">\n",
    "<img src=\"convLayer7.png\">\n",
    "\n",
    "- Red neuronal:\n",
    "\n",
    "<img src=\"fcLayer.png\">\n",
    "\n",
    "- Esquema de una red neuronal convolucional:\n",
    "\n",
    "<img src=\"cnnClasificacion.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a TensorFlow\n",
    "\n",
    "- Tensor: generalización de los conceptos de escalar, vector y matriz.\n",
    "\n",
    "<img src=\"tensores.jpg\">\n",
    "\n",
    "- Grafo computacional:\n",
    "\n",
    "<img src=\"computationalGraph.png\">\n",
    "\n",
    "- Tensorflow:\n",
    " - Software libre (licencia Apache 2.0).\n",
    " - Desarrollado originalmente por el equipo de _Google Brain_\n",
    " - Libreria _open source_ para la computación numérica usando grafos de flujo de datos. Ideal para _machine learning_ y _deep learning_.\n",
    " \n",
    "<img src=\"tensorflow1.png\">\n",
    "<img src=\"tensorflow2.png\">\n",
    "<img src=\"tensorflow3.png\">\n",
    "<img src=\"tensorflow4.png\">\n",
    "<img src=\"tensorflow5.jpg\">\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer ejemplo de TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    }
   ],
   "source": [
    "# Multiplicación de dos numeros en TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Creamos nuestro grafo con las operaciones a realizar\n",
    "a = tf.placeholder(\"float\")\n",
    "b = tf.placeholder(\"float\")\n",
    "\n",
    "y = tf.multiply(a, b)\n",
    "\n",
    "# Creamos una Session para poder trabajar con nuestro grafo.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Le pedimos a tensorflow que nos calcule y, para ello, debemos asignar los valores de a y b.\n",
    "print(sess.run(y, feed_dict={a: 3, b: 3}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Explorando el dataset MNIST\n",
    "- Disponible desde tensorflow.\n",
    "- Contiene 55,000 ejemplos de entrenamiento y 10,000 ejemplos para test. Los dígitos tienen todos el mismo tamaño y estan centrados en la imagen. De modo que, cada ejemplo es representado por una matriz de 2 dimensiones de tamaño 28x28 con valores entre 0 y 1.\n",
    "\n",
    "## Imagenes de entrenamiento\n",
    "\n",
    "![mnist.train.xs](https://www.tensorflow.org/versions/master/images/mnist-train-xs.png)\n",
    "\n",
    "## Labels de entrenamient\n",
    "\n",
    "![mnist.train.ys](https://www.tensorflow.org/versions/master/images/mnist-train-ys.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Con esta orden descargamos el dataset MNIST en el directorio donde esta el _notebook_, mediante el parametro one_hot=True,\n",
    "# le pedimos a tensorflow que transforme las clases de los dígitos (0,1,2,3,4,5,6,7,8,9) a un vector con el mismo tamaño\n",
    "# que el número de clases y con un 1 en la posicion correspondiente a la clase del dígito.\n",
    "\n",
    "# Clase 0 => [1,0,0,0,0,0,0,0,0,0]\n",
    "# Clase 5 => [0,0,0,0,0,1,0,0,0,0]\n",
    "# Clase 9 => [0,0,0,0,0,0,0,0,0,1]\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./mnist/\", one_hot=True)\n",
    "\n",
    "# Cargamos los datos\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data shape\n",
    "\n",
    "- Cada imagen tiene un tamaño de 784 (28x28).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (55000, 784)\n",
      "y_train:  (55000, 10)\n",
      "x_test:  (10000, 784)\n",
      "y_test:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print \"x_train: \", x_train.shape\n",
    "print \"y_train: \", y_train.shape\n",
    "print \"x_test: \", x_test.shape\n",
    "print \"y_test: \", y_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visalización del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD/CAYAAADhYy38AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnUCGThAEYSeQoRMEQdgJZOgEQRB2wv8Bc2O+ggSunzQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f583f378750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_mnist(data, classes):\n",
    "    \n",
    "    for i in range(10):\n",
    "        idxs = (classes == i)\n",
    "        \n",
    "        # get 10 images for class i\n",
    "        images = data[idxs][0:10]\n",
    "            \n",
    "        for j in range(5):   \n",
    "            plt.subplot(5, 10, i + j*10 + 1)\n",
    "            plt.imshow(images[j].reshape(28, 28), cmap='gray')\n",
    "            # print a title only once for each class\n",
    "            if j == 0:\n",
    "                plt.title(i)\n",
    "            plt.axis('off')\n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "classes = np.argmax(y_train, 1)\n",
    "plot_mnist(x_train, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Afrontemos el problema con una red neuronal\n",
    "\n",
    "- Cálculo del error para una red con softmax => Usar cross-entropy:\n",
    "\n",
    "<img src=\"crossEntropy.jpg\">\n",
    "\n",
    "- Estructura de nuestra red:\n",
    "\n",
    "<img src=\"nn.png\">\n",
    "\n",
    "- En tensorflow:\n",
    "\n",
    " - Grafo:\n",
    "![](https://www.tensorflow.org/versions/master/images/softmax-regression-scalargraph.png)\n",
    "\n",
    " - Operación:\n",
    "![](https://www.tensorflow.org/versions/master/images/softmax-regression-vectorequation.png)\n",
    "\n",
    " - Esperamos obtener:\n",
    "azules: pesos positivos, rojo: pesos negativos.\n",
    "![](https://www.tensorflow.org/versions/master/images/softmax-weights.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss it. 0 = 2.30259\n",
      "Loss it. 100 = 0.428096\n",
      "Loss it. 200 = 0.246036\n",
      "Loss it. 300 = 0.314328\n",
      "Loss it. 400 = 0.429943\n",
      "Loss it. 500 = 0.353608\n",
      "Loss it. 600 = 0.300348\n",
      "Loss it. 700 = 0.547566\n",
      "Loss it. 800 = 0.456533\n",
      "Loss it. 900 = 0.426243\n",
      "Loss it. 1000 = 0.322979\n",
      "Accuracy = 0.9199\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Creamos el modelo\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # None permite poder suministrar cualquier valor en la dimensión que se encuentra\n",
    "W = tf.Variable(tf.zeros([784, 10])) # Inicializamos todos los pesos a 0\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.matmul(x, W) + b # Predicción de nuestro modelo\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 10]) # Salida esperada\n",
    "\n",
    "\n",
    "# Definimos el error\n",
    "cross_entropy = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "\n",
    "# Un paso en el entrenamiento consistirá en decirle a tf que minimice el cross_entropy usando el gradient descent\n",
    "# Calculará la salida de la red y ajustará los valores de los pesos gracias al backpropagation.\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cross_entropy)\n",
    "\n",
    "# Preparamos tensorflow para realizar el entrenamiento\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Antes de comenzar es necesario inicializar todas las variables que hayan en el grafo.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "# Entrenamiento\n",
    "for i in range(1001):\n",
    "    \n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    loss, _ = sess.run([cross_entropy, train_step], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"Loss it. \" + str(i) + \" = \" + str(loss))\n",
    "\n",
    "# Probamos el modelo entrenado sobre el conjunto de TEST\n",
    "correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(y), 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print \"Accuracy =\", sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "y_: mnist.test.labels})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen elegida: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5864d44390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase predicha:  [4]\n",
      "Salida de nuestro modelo:  [[ 0.0003573   0.00000177  0.00410978  0.00010177  0.95782745  0.00037524\n",
      "   0.00302254  0.00591056  0.00534259  0.02295091]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "# Prueba sobre una imagen concreta de test \n",
    "idx = 4\n",
    "\n",
    "print \"Imagen elegida: \"\n",
    "plt.imshow(mnist.test.images[idx,:].reshape(28, 28), cmap='gray')\n",
    "plt.title(mnist.test.labels[idx, :])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "salidaModelo, prediccion = sess.run([tf.nn.softmax(y), tf.argmax(tf.nn.softmax(y), 1)],feed_dict={x: mnist.test.images[idx,:].reshape(1,784),\n",
    "y_: mnist.test.labels[idx, :].reshape(1,10)} )\n",
    "\n",
    "print \"Clase predicha: \", prediccion\n",
    "print \"Salida de nuestro modelo: \", salidaModelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podemos mejorar los resultados si utilizamos una red neuronal convolucional: _LeNet5_*\n",
    "\n",
    "- Vamos a probar una modificación de esta red para mejorar los resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def deepnn(x):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "    x: an input tensor with the dimensions (N_examples, 784), where 784 is the\n",
    "    number of pixels in a standard MNIST image.\n",
    "\n",
    "    Returns:\n",
    "    A tuple (y, keep_prob). y is a tensor of shape (N_examples, 10), with values\n",
    "    equal to the logits of classifying the digit into one of 10 classes (the\n",
    "    digits 0-9). keep_prob is a scalar placeholder for the probability of\n",
    "    dropout.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reshape to use within a convolutional neural net.\n",
    "    # Last dimension is for \"features\" - there is only one here, since images are\n",
    "    # grayscale -- it would be 3 for an RGB image, 4 for RGBA, etc.\n",
    "    with tf.name_scope('reshape'):\n",
    "        x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "    # First convolutional layer - maps one grayscale image to 32 feature maps.\n",
    "    with tf.name_scope('conv1'):\n",
    "        W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "        b_conv1 = bias_variable([32])\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "    # Pooling layer - downsamples by 2X.\n",
    "    with tf.name_scope('pool1'):\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "    # Second convolutional layer -- maps 32 feature maps to 64.\n",
    "    with tf.name_scope('conv2'):\n",
    "        W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "        b_conv2 = bias_variable([64])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "    # Second pooling layer.\n",
    "    with tf.name_scope('pool2'):\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "    # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image\n",
    "    # is down to 7x7x64 feature maps -- maps this to 1024 features.\n",
    "    with tf.name_scope('fc1'):\n",
    "        W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "        b_fc1 = bias_variable([1024])\n",
    "\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    # Dropout - controls the complexity of the model, prevents co-adaptation of\n",
    "    # features.\n",
    "    #with tf.name_scope('dropout'):\n",
    "    #    keep_prob = tf.placeholder(tf.float32)\n",
    "    #    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "    # Map the 1024 features to 10 classes, one for each digit\n",
    "    with tf.name_scope('fc2'):\n",
    "        W_fc2 = weight_variable([1024, 10])\n",
    "        b_fc2 = bias_variable([10])\n",
    "\n",
    "        #y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "        y_conv = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "        \n",
    "        return y_conv#, keep_prob\n",
    "\n",
    "\n",
    "def conv2d(x, W):\n",
    "    \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    \"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME') # strides indica el paso del kernel por cada dimension.\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.09375, training loss 11.3822\n",
      "step 10, training accuracy 0.25, training loss 3.31112\n",
      "step 20, training accuracy 0.4375, training loss 1.67264\n",
      "step 30, training accuracy 0.71875, training loss 0.880312\n",
      "step 40, training accuracy 0.625, training loss 1.00942\n",
      "step 50, training accuracy 0.796875, training loss 0.596609\n",
      "step 60, training accuracy 0.890625, training loss 0.531125\n",
      "step 70, training accuracy 0.828125, training loss 0.534666\n",
      "step 80, training accuracy 0.703125, training loss 0.803484\n",
      "step 90, training accuracy 0.75, training loss 0.704864\n",
      "step 100, training accuracy 0.8125, training loss 0.408018\n",
      "step 110, training accuracy 0.875, training loss 0.3892\n",
      "step 120, training accuracy 0.890625, training loss 0.392752\n",
      "step 130, training accuracy 0.828125, training loss 0.491598\n",
      "step 140, training accuracy 0.890625, training loss 0.406494\n",
      "step 150, training accuracy 0.78125, training loss 0.605432\n",
      "step 160, training accuracy 0.828125, training loss 0.428715\n",
      "step 170, training accuracy 0.984375, training loss 0.143198\n",
      "step 180, training accuracy 0.9375, training loss 0.380655\n",
      "step 190, training accuracy 0.90625, training loss 0.295834\n",
      "step 200, training accuracy 0.859375, training loss 0.350801\n",
      "step 210, training accuracy 0.90625, training loss 0.309413\n",
      "step 220, training accuracy 0.890625, training loss 0.361703\n",
      "step 230, training accuracy 0.875, training loss 0.358273\n",
      "step 240, training accuracy 0.921875, training loss 0.236903\n",
      "step 250, training accuracy 0.9375, training loss 0.192945\n",
      "step 260, training accuracy 0.859375, training loss 0.334644\n",
      "step 270, training accuracy 0.890625, training loss 0.433908\n",
      "step 280, training accuracy 0.890625, training loss 0.483828\n",
      "step 290, training accuracy 0.96875, training loss 0.139783\n",
      "step 300, training accuracy 0.90625, training loss 0.227158\n",
      "step 310, training accuracy 0.921875, training loss 0.264016\n",
      "step 320, training accuracy 0.9375, training loss 0.193899\n",
      "step 330, training accuracy 0.953125, training loss 0.176566\n",
      "step 340, training accuracy 0.96875, training loss 0.118824\n",
      "step 350, training accuracy 0.921875, training loss 0.214371\n",
      "step 360, training accuracy 0.890625, training loss 0.307391\n",
      "step 370, training accuracy 0.96875, training loss 0.124392\n",
      "step 380, training accuracy 0.96875, training loss 0.165062\n",
      "step 390, training accuracy 0.921875, training loss 0.3848\n",
      "step 400, training accuracy 0.9375, training loss 0.273621\n",
      "step 410, training accuracy 0.953125, training loss 0.263346\n",
      "step 420, training accuracy 0.921875, training loss 0.149187\n",
      "step 430, training accuracy 0.96875, training loss 0.1244\n",
      "step 440, training accuracy 0.90625, training loss 0.219256\n",
      "step 450, training accuracy 0.9375, training loss 0.253267\n",
      "step 460, training accuracy 0.921875, training loss 0.216394\n",
      "step 470, training accuracy 0.890625, training loss 0.247615\n",
      "step 480, training accuracy 0.984375, training loss 0.0748707\n",
      "step 490, training accuracy 0.921875, training loss 0.156129\n",
      "step 500, training accuracy 0.953125, training loss 0.112785\n",
      "step 510, training accuracy 0.984375, training loss 0.0721823\n",
      "step 520, training accuracy 0.984375, training loss 0.115917\n",
      "step 530, training accuracy 0.96875, training loss 0.0753278\n",
      "step 540, training accuracy 0.921875, training loss 0.295235\n",
      "step 550, training accuracy 0.953125, training loss 0.148827\n",
      "step 560, training accuracy 0.953125, training loss 0.216033\n",
      "step 570, training accuracy 0.890625, training loss 0.231981\n",
      "step 580, training accuracy 0.953125, training loss 0.165289\n",
      "step 590, training accuracy 0.9375, training loss 0.183007\n",
      "step 600, training accuracy 0.96875, training loss 0.218835\n",
      "step 610, training accuracy 0.96875, training loss 0.117187\n",
      "step 620, training accuracy 0.953125, training loss 0.11631\n",
      "step 630, training accuracy 0.96875, training loss 0.101153\n",
      "step 640, training accuracy 0.96875, training loss 0.130705\n",
      "step 650, training accuracy 0.96875, training loss 0.0923472\n",
      "step 660, training accuracy 0.984375, training loss 0.0643766\n",
      "step 670, training accuracy 0.984375, training loss 0.0668795\n",
      "step 680, training accuracy 0.96875, training loss 0.0868673\n",
      "step 690, training accuracy 0.953125, training loss 0.122997\n",
      "step 700, training accuracy 0.96875, training loss 0.112075\n",
      "step 710, training accuracy 0.9375, training loss 0.16382\n",
      "step 720, training accuracy 0.9375, training loss 0.177998\n",
      "step 730, training accuracy 0.96875, training loss 0.0620269\n",
      "step 740, training accuracy 0.96875, training loss 0.179808\n",
      "step 750, training accuracy 0.96875, training loss 0.102854\n",
      "step 760, training accuracy 0.984375, training loss 0.0734631\n",
      "step 770, training accuracy 0.953125, training loss 0.142104\n",
      "step 780, training accuracy 0.9375, training loss 0.223494\n",
      "step 790, training accuracy 0.953125, training loss 0.127855\n",
      "step 800, training accuracy 1, training loss 0.0444288\n",
      "step 810, training accuracy 0.984375, training loss 0.0658019\n",
      "step 820, training accuracy 1, training loss 0.0285874\n",
      "step 830, training accuracy 0.96875, training loss 0.102233\n",
      "step 840, training accuracy 0.96875, training loss 0.0708229\n",
      "step 850, training accuracy 0.953125, training loss 0.0979384\n",
      "step 860, training accuracy 0.921875, training loss 0.192412\n",
      "step 870, training accuracy 0.9375, training loss 0.267463\n",
      "step 880, training accuracy 0.953125, training loss 0.0985681\n",
      "step 890, training accuracy 0.96875, training loss 0.126961\n",
      "step 900, training accuracy 0.953125, training loss 0.119134\n",
      "step 910, training accuracy 0.890625, training loss 0.342358\n",
      "step 920, training accuracy 0.984375, training loss 0.0879414\n",
      "step 930, training accuracy 0.984375, training loss 0.0749022\n",
      "step 940, training accuracy 0.9375, training loss 0.151303\n",
      "step 950, training accuracy 0.984375, training loss 0.0897622\n",
      "step 960, training accuracy 0.953125, training loss 0.0840513\n",
      "step 970, training accuracy 0.953125, training loss 0.136725\n",
      "step 980, training accuracy 1, training loss 0.0254933\n",
      "step 990, training accuracy 0.96875, training loss 0.212953\n",
      "step 1000, training accuracy 0.9375, training loss 0.253924\n",
      "step 1010, training accuracy 0.953125, training loss 0.121586\n",
      "step 1020, training accuracy 0.96875, training loss 0.0738702\n",
      "step 1030, training accuracy 0.984375, training loss 0.0766701\n",
      "step 1040, training accuracy 0.984375, training loss 0.0498171\n",
      "step 1050, training accuracy 0.953125, training loss 0.120113\n",
      "step 1060, training accuracy 1, training loss 0.0273246\n",
      "step 1070, training accuracy 0.96875, training loss 0.0576974\n",
      "step 1080, training accuracy 0.96875, training loss 0.0976159\n",
      "step 1090, training accuracy 0.953125, training loss 0.108371\n",
      "step 1100, training accuracy 0.984375, training loss 0.0639344\n",
      "step 1110, training accuracy 0.984375, training loss 0.0725029\n",
      "step 1120, training accuracy 1, training loss 0.026152\n",
      "step 1130, training accuracy 0.96875, training loss 0.0577126\n",
      "step 1140, training accuracy 0.984375, training loss 0.061231\n",
      "step 1150, training accuracy 0.90625, training loss 0.229796\n",
      "step 1160, training accuracy 0.984375, training loss 0.0587861\n",
      "step 1170, training accuracy 0.984375, training loss 0.0535083\n",
      "step 1180, training accuracy 0.96875, training loss 0.114379\n",
      "step 1190, training accuracy 0.984375, training loss 0.046159\n",
      "step 1200, training accuracy 0.96875, training loss 0.0998121\n",
      "step 1210, training accuracy 1, training loss 0.023263\n",
      "step 1220, training accuracy 0.984375, training loss 0.0796591\n",
      "step 1230, training accuracy 1, training loss 0.0407613\n",
      "step 1240, training accuracy 0.953125, training loss 0.128366\n",
      "step 1250, training accuracy 0.984375, training loss 0.0472484\n",
      "step 1260, training accuracy 0.953125, training loss 0.0819784\n",
      "step 1270, training accuracy 1, training loss 0.0234422\n",
      "step 1280, training accuracy 0.984375, training loss 0.0679384\n",
      "step 1290, training accuracy 0.9375, training loss 0.189796\n",
      "step 1300, training accuracy 0.953125, training loss 0.101617\n",
      "step 1310, training accuracy 0.984375, training loss 0.0564026\n",
      "step 1320, training accuracy 0.984375, training loss 0.0749291\n",
      "step 1330, training accuracy 0.984375, training loss 0.202681\n",
      "step 1340, training accuracy 0.984375, training loss 0.0454174\n",
      "step 1350, training accuracy 0.9375, training loss 0.165826\n",
      "step 1360, training accuracy 0.953125, training loss 0.0881759\n",
      "step 1370, training accuracy 0.953125, training loss 0.120756\n",
      "step 1380, training accuracy 0.984375, training loss 0.12508\n",
      "step 1390, training accuracy 0.96875, training loss 0.121316\n",
      "step 1400, training accuracy 0.984375, training loss 0.0518431\n",
      "step 1410, training accuracy 0.984375, training loss 0.0732564\n",
      "step 1420, training accuracy 1, training loss 0.0291143\n",
      "step 1430, training accuracy 0.984375, training loss 0.0667425\n",
      "step 1440, training accuracy 0.953125, training loss 0.118222\n",
      "step 1450, training accuracy 0.984375, training loss 0.109383\n",
      "step 1460, training accuracy 0.96875, training loss 0.0561662\n",
      "step 1470, training accuracy 0.96875, training loss 0.172075\n",
      "step 1480, training accuracy 0.953125, training loss 0.158271\n",
      "step 1490, training accuracy 0.984375, training loss 0.035949\n",
      "step 1500, training accuracy 0.984375, training loss 0.0532766\n",
      "step 1510, training accuracy 1, training loss 0.0172163\n",
      "step 1520, training accuracy 0.984375, training loss 0.0330528\n",
      "step 1530, training accuracy 0.96875, training loss 0.0676742\n",
      "step 1540, training accuracy 1, training loss 0.0255456\n",
      "step 1550, training accuracy 0.984375, training loss 0.048826\n",
      "step 1560, training accuracy 1, training loss 0.0290343\n",
      "step 1570, training accuracy 1, training loss 0.0330752\n",
      "step 1580, training accuracy 0.9375, training loss 0.165726\n",
      "step 1590, training accuracy 1, training loss 0.0415515\n",
      "step 1600, training accuracy 1, training loss 0.0200027\n",
      "step 1610, training accuracy 1, training loss 0.0165358\n",
      "step 1620, training accuracy 0.984375, training loss 0.0637815\n",
      "step 1630, training accuracy 1, training loss 0.0266937\n",
      "step 1640, training accuracy 0.96875, training loss 0.0784471\n",
      "step 1650, training accuracy 0.96875, training loss 0.094959\n",
      "step 1660, training accuracy 0.953125, training loss 0.103016\n",
      "step 1670, training accuracy 0.96875, training loss 0.099828\n",
      "step 1680, training accuracy 0.96875, training loss 0.0599256\n",
      "step 1690, training accuracy 0.953125, training loss 0.0871011\n",
      "step 1700, training accuracy 1, training loss 0.0328049\n",
      "step 1710, training accuracy 1, training loss 0.0329473\n",
      "step 1720, training accuracy 1, training loss 0.0226308\n",
      "step 1730, training accuracy 1, training loss 0.0341901\n",
      "step 1740, training accuracy 1, training loss 0.0251944\n",
      "step 1750, training accuracy 0.984375, training loss 0.0635313\n",
      "step 1760, training accuracy 0.984375, training loss 0.0600295\n",
      "step 1770, training accuracy 0.953125, training loss 0.11074\n",
      "step 1780, training accuracy 0.96875, training loss 0.0799098\n",
      "step 1790, training accuracy 0.96875, training loss 0.0309291\n",
      "step 1800, training accuracy 0.953125, training loss 0.110606\n",
      "step 1810, training accuracy 0.984375, training loss 0.0615435\n",
      "step 1820, training accuracy 0.96875, training loss 0.0691468\n",
      "step 1830, training accuracy 0.984375, training loss 0.0350489\n",
      "step 1840, training accuracy 0.953125, training loss 0.250777\n",
      "step 1850, training accuracy 0.96875, training loss 0.127116\n",
      "step 1860, training accuracy 0.984375, training loss 0.0457854\n",
      "step 1870, training accuracy 0.984375, training loss 0.0540552\n",
      "step 1880, training accuracy 0.96875, training loss 0.0794511\n",
      "step 1890, training accuracy 0.96875, training loss 0.0893334\n",
      "step 1900, training accuracy 1, training loss 0.019791\n",
      "step 1910, training accuracy 0.984375, training loss 0.0460322\n",
      "step 1920, training accuracy 0.984375, training loss 0.0752893\n",
      "step 1930, training accuracy 0.984375, training loss 0.103399\n",
      "step 1940, training accuracy 0.96875, training loss 0.148776\n",
      "step 1950, training accuracy 1, training loss 0.0451868\n",
      "step 1960, training accuracy 1, training loss 0.030398\n",
      "step 1970, training accuracy 0.984375, training loss 0.0635339\n",
      "step 1980, training accuracy 1, training loss 0.0304123\n",
      "step 1990, training accuracy 0.984375, training loss 0.0371064\n",
      "step 2000, training accuracy 0.96875, training loss 0.0654747\n",
      "test accuracy 0.9809\n"
     ]
    }
   ],
   "source": [
    "sess.close()\n",
    "\n",
    "# Create the model\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# Build the graph for the deep net\n",
    "y_conv = deepnn(x)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_,\n",
    "                                                        logits=y_conv)\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "with tf.name_scope('adam_optimizer'):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cross_entropy)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(tf.nn.softmax(y_conv), 1), tf.argmax(y_, 1))\n",
    "    correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "    accuracy = tf.reduce_mean(correct_prediction)\n",
    "\n",
    "    \n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(2001):\n",
    "\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(64)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        train_accuracy = sess.run(accuracy, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        train_cross_entropy = sess.run(cross_entropy, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "        print('step %d, training accuracy %g, training loss %g' % (i, train_accuracy, train_cross_entropy))\n",
    "\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "print('test accuracy %g' % sess.run(accuracy, feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen elegida: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFob0XQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efeb0316490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase predicha:  [4]\n",
      "Salida de nuestro modelo:  [[ 0.00001222  0.00008962  0.0000054   0.00004258  0.9920277   0.00033867\n",
      "   0.0002621   0.00004732  0.00065776  0.00651666]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "# Prueba sobre una imagen concreta de test \n",
    "idx = 65\n",
    "\n",
    "print \"Imagen elegida: \"\n",
    "plt.imshow(mnist.test.images[idx,:].reshape(28, 28), cmap='gray')\n",
    "plt.title(mnist.test.labels[idx, :])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "salidaModelo, prediccion = sess.run([tf.nn.softmax(y_conv), tf.argmax(tf.nn.softmax(y_conv), 1)],feed_dict={x: mnist.test.images[idx,:].reshape(1,784),\n",
    "y_: mnist.test.labels[idx, :].reshape(1,10)} )\n",
    "\n",
    "print \"Clase predicha: \", prediccion\n",
    "print \"Salida de nuestro modelo: \", salidaModelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
